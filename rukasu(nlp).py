# -*- coding: utf-8 -*-
"""rukasu(nlp).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DmUfl0_t0l6EAQ-OszWHXHTK3I37eB2S

## Importing all dependencies
"""

import numpy as np
import pandas as pd
# import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import nltk
# from sklearn.feature_extraction.text import CountVectorizer
from wordcloud import WordCloud,STOPWORDS
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import re,string,unicodedata
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score
from sklearn.model_selection import train_test_split
from string import punctuation
# from nltk import pos_tag
from nltk.corpus import wordnet
# import re
import warnings
warnings.filterwarnings('ignore')
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""## Loading of Data"""

df = pd.read_csv(r'/content/IMDB-Dataset.csv',encoding='latin-1')
df.head()

"""## Data Cleaning and Preprocessing"""

#Customize stopword as per data
nltk.download('stopwords')
from nltk.corpus import stopwords
stop_words = stopwords.words('english')
new_stopwords = ["would","shall","could","might"]
stop_words.extend(new_stopwords)
stop_words.remove("not")
stop_words=set(stop_words)
print(stop_words)

'''-----------------------------Data Cleaning and Preprocessing pipeline----------------------------------'''

#Removing special character
def remove_special_character(content):
    return re.sub('\W+',' ', content )#re.sub('\[[^&@#!]]*\]', '', content)

# Removing URL's
def remove_url(content):
    return re.sub(r'http\S+', '', content)

#Removing the stopwords from text
def remove_stopwords(content):
    clean_data = []
    for i in content.split():
        if i.strip().lower() not in stop_words and i.strip().lower().isalpha():
            clean_data.append(i.strip().lower())
    return " ".join(clean_data)

# Expansion of english contractions
def contraction_expansion(content):
    content = re.sub(r"won\'t", "would not", content)
    content = re.sub(r"can\'t", "can not", content)
    content = re.sub(r"don\'t", "do not", content)
    content = re.sub(r"shouldn\'t", "should not", content)
    content = re.sub(r"needn\'t", "need not", content)
    content = re.sub(r"hasn\'t", "has not", content)
    content = re.sub(r"haven\'t", "have not", content)
    content = re.sub(r"weren\'t", "were not", content)
    content = re.sub(r"mightn\'t", "might not", content)
    content = re.sub(r"didn\'t", "did not", content)
    content = re.sub(r"n\'t", " not", content)
    '''content = re.sub(r"\'re", " are", content)
    content = re.sub(r"\'s", " is", content)
    content = re.sub(r"\'d", " would", content)
    content = re.sub(r"\'ll", " will", content)
    content = re.sub(r"\'t", " not", content)
    content = re.sub(r"\'ve", " have", content)
    content = re.sub(r"\'m", " am", content)'''
    return content

#Data preprocessing
def data_cleaning(content):
    content = contraction_expansion(content)
    content = remove_special_character(content)
    content = remove_url(content)

    content = remove_stopwords(content)
    return content

pd.options.display.max_colwidth = 1000
#Data cleaning
df['Reviews_clean']=df['Reviews'].apply(data_cleaning)
df.head(5)

"""# Feature Engineering"""

#Mapping rating data to Binary label 1 (+ve) if rating >=7 and 0 (-ve) if rating <=4 and 2 (neutral) if rating = 5 or 6
df['Label'] = df['Ratings'].apply(lambda x: '1' if x >= 7 else ('0' if x<=4 else '2'))

#Removing
df=df[df.Label<'3']
data=df[['Reviews_clean','Reviews','Ratings','Label']]
print(data['Label'].value_counts())

#Importing dependencies for feature engineering
import sys
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import pandas as pd
from prettytable import PrettyTable
from nltk import word_tokenize
from nltk.stem import WordNetLemmatizer

"""## Lemmatization"""

# lemmatization of word
class LemmaTokenizer(object):
    def __init__(self):
        self.wordnetlemma = WordNetLemmatizer()
    def __call__(self, reviews):
        return [self.wordnetlemma.lemmatize(word) for word in word_tokenize(reviews)]

nltk.download('wordnet')
nltk.download('punkt')
train,test=train_test_split(data,test_size=.3,random_state=42, shuffle=True)
#countvect = CountVectorizer(analyzer = "word", tokenizer = LemmaTokenizer(), ngram_range=(1,3), min_df=10,max_features=5000)
tfidfvect = TfidfVectorizer(analyzer = "word", tokenizer = LemmaTokenizer(), ngram_range=(1,3),min_df=10,max_features=2000)
#x_train_count = countvect.fit_transform(train['Reviews_clean']).toarray()
#x_test_count = countvect.transform(test['Reviews_clean']).toarray()
x_train_tfidf = tfidfvect.fit_transform(train['Reviews_clean']).toarray()
x_test_tfidf = tfidfvect.transform(test['Reviews_clean']).toarray()

y_train = train['Label']
y_test = test['Label']





"""## Model Evaluation"""

# Import prerequisite libraries
import sys
import numpy as np
import scipy as sp
import sklearn as sk
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score,precision_recall_curve
from sklearn.pipeline import make_pipeline
from sklearn.pipeline import Pipeline

"""## Logistic Regression Model"""

'''model_1 = Pipeline(
    steps=[
        #best base model("classifier", LogisticRegression(penalty='l2',dual=False, tol=0.0001, C=1.0, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None)),
    ("classifier", LogisticRegression())]
)'''
# model_1=LogisticRegression(penalty='l2',dual=False, tol=0.0001, C=10, solver='lbfgs', max_iter=200, multi_class='auto', verbose=0, warm_start=False, n_jobs=None)
model_2=Pipeline(
    steps=[
        #best base model("classifier", LogisticRegression(penalty='l2',dual=False, tol=0.0001, C=1.0, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None)),
    ('vect',TfidfVectorizer(analyzer = "word", tokenizer = LemmaTokenizer(), ngram_range=(1,3),min_df=10,max_features=2000)),("classifier", LogisticRegression(penalty='l2',dual=False, tol=0.0001, C=10, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None))
])

"""## Training of Logistic Regression Model"""

# %%time
# model_1.fit(x_train_tfidf,y_train)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# model_2.fit(train['Reviews_clean'],y_train)

"""## Evaluation on multiple metrics dataset"""

# %%time
# print("Precision Score for Logistic Regression: %s" % precision_score(y_test,model_1.predict(x_test_tfidf),average='micro'))
# print("Recall Score for Logistic Regression: %s" % recall_score(y_test,model_1.predict(x_test_tfidf),average='micro'))
# print("AUC Score for Logistic Regression: %s" % roc_auc_score(y_test,model_1.predict_proba(x_test_tfidf)[:,1],multi_class='ovo',average='macro'))
# f1_score_1 =f1_score(y_test,model_1.predict(x_test_tfidf),average="weighted")
# print("F1 Score for Logistic Regression: %s" % f1_score_1)
# print("Accuracy Score for Logistic Regression: %s" % accuracy_score(y_test,model_1.predict(x_test_tfidf)))
print("Precision Score for Logistic Regression Pipeline: %s" % precision_score(y_test,model_2.predict(test['Reviews_clean']),average='micro'))
print("Recall Score for Logistic Regression Pipeline: %s" % recall_score(y_test,model_2.predict(test['Reviews_clean']),average='micro'))
print("AUC Score for Logistic Regression Pipeline: %s" % roc_auc_score(y_test,model_2.predict_proba(test['Reviews_clean'])[:,1],multi_class='ovo',average='macro'))
f1_score_2 =f1_score(y_test,model_2.predict(test['Reviews_clean']),average="weighted")
print("F1 Score for Logistic Regression Pipeline: %s" % f1_score_2)
print("Accuracy Score for Logistic Regression Pipeline: %s" % accuracy_score(y_test,model_2.predict(test['Reviews_clean'])))

# y_predict=model_.predict(x_test_tfidf)
# y_predict_prob=model_2.predict_proba(x_test_tfidf)[:,1]

# y_test_list=y_test.tolist()
# y_predict_list=y_predict.tolist()
# test_list=test['Reviews_clean'].tolist()
# rating_list=test['Ratings'].tolist()

"""## Confusion metrics"""

# def confusion_matrix_plot(y_test,y_score):
#     confmatrix = confusion_matrix(y_test,y_score)
#     fig, ax = plt.subplots(figsize=(8, 8))
#     ax.imshow(confmatrix)
#     ax.grid(False)
#     ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))
#     ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))
#     ax.set_ylim(1.5, -0.5)
#     for i in range(2):
#         for j in range(2):
#             ax.text(j, i, confmatrix[i, j], ha='center', va='center', color='red')
#     plt.show()

# confusion_matrix_plot(y_test,y_predict)

# import joblib

# pth=r'/content/drive/MyDrive/sentimentanalysis/models/model/classifier.pkl'
# joblib.dump(model_2,pth,compress=True)

# pip install colorama

"""## Analyzing False Positive and False Negative"""

# from colorama import Fore, Back, Style
# fn_dict={}
# fp_dict={}
# for i in range(0, len(y_test_list)):
#     if ((y_test_list[i]=='0') & (y_predict[i]=='1')):
#         fp_dict[i]=[test_list[i],rating_list[i]]
#     elif((y_test_list[i]=='1') & (y_predict[i]=='0')):
#         fn_dict[i]=[test_list[i],rating_list[i]]
#     else:
#         pass
#     i+=1
# for k,v in fp_dict.items():
#     if v[1]<=2:
#         print(Fore.RED +'False Positive: %s %s'%(k,v))
# for k,v in fn_dict.items():
#     if v[1]>=9:
#         print(Fore.GREEN +'False Negative: %s %s'%(k,v))

"""# XAI: Explainable AI by Shap and LIME

## Explain Marginal Contribution of Features by Shap
"""

pip install shap

!pip install -U shap

import shap

shap.initjs()

# explainer = shap.Explainer(model_1, x_train_tfidf, feature_names=tfidfvect.get_feature_names())
# shap_values = explainer(x_test_tfidf)
# Assuming you have a list of feature names
feature_names = tfidfvect.get_feature_names_out()

# Create the explainer
explainer = shap.Explainer(model_1, x_train_tfidf, feature_names=feature_names)

# Compute SHAP values
shap_values = explainer(x_test_tfidf)

shap.plots.beeswarm(shap_values)

"""## Visualizing Marginal Contribution of Features"""

ind = 4443
print('Probability Score %s' %y_predict_prob[ind])
shap.plots.force(shap_values[ind])

y_test_list=y_test.tolist()
print("Positive" if y_test_list[ind] else "Negative", "Review:")
print(test_list[ind])

"""## Visualizing Marginal Contribution of Features for False Positive"""

ind = 111
print('Probability Score %s' %y_predict_prob[ind])
shap.plots.force(shap_values[ind])

y_test_list=y_test.tolist()
print("Positive" if y_test_list[ind] else "Negative", "Review:")
print(test_list[ind])

"""## Visualizing Marginal Contribution of Features for False Negative"""

ind = 7599
print('Probability Score %s' %y_predict_prob[ind])
shap.plots.force(shap_values[ind])

y_test_list=y_test.tolist()
print("Positive" if y_test_list[ind] else "Negative", "Review:")
print(test_list[ind])

"""## Explain feature impact on Prediction by LIME"""

# idx=7599
# output = model_2.predict([test_list[idx]])
# print(output)

!pip install lime

# test_list[1]

from lime.lime_text import LimeTextExplainer
class_names = [0,1]
explainer = LimeTextExplainer(class_names=class_names)
# exp = explainer.explain_instance(test_list[idx], model_2.predict_proba, num_features = 100,top_labels=2)
# print('New document id: %d' % idx)
# print('Predicted Label =', model_2.predict([test_list[idx]]))
# print('Predicted probabilites =', model_2.predict_proba([test_list[idx]]))
# print('Actual Label: %s' % y_test_list[idx])
# print(exp.available_labels())

"""## Explain feature impact on False Positive by LIME

## Explain feature impact on False Positive by LIMEÂ¶
"""

test=input()
exp = explainer.explain_instance(test, model_2.predict_proba, num_features = 100,top_labels=2)
exp.show_in_notebook(text=True)

!pip install anvil-uplink

import anvil.server
import json

anvil.server.connect("server_6UVGAXQMKRARFSC6ROWJSUNC-GZSMCQ4QQXUEO3Q")

@anvil.server.callable
def predict_sentiment(test):
  # result=[]
  class_names = [0,1]
  explainer = LimeTextExplainer(class_names=class_names)
  exp = explainer.explain_instance(test, model_2.predict_proba, num_features = 100,top_labels=2)
  prob= model_2.predict_proba([test])
  if((prob[0][0]-prob[0][1]==0.05) | (prob[0][1]-prob[0][0]==0.05)):
    sentiment="\U0001F604'NEUTRAL'"
  elif(prob[0][0]>prob[0][1]):
    sentiment="\U0001F61E'NEGATIVE'"
  else:
    sentiment="\U0001F604'POSITIVE'"
  # result[0]=sentimen
  # result[1]=json.dumps(exp.as_dict())
  return sentiment

anvil.server.wait_forever()

import nltk
nltk.download('punkt')

@anvil.server.callable

def summarize_text(text):
  # Tokenize the text into sentences and words
  sentences = text.split('.')  # Split text into sentences (you can use a more advanced sentence tokenizer)
  words = text.split()  # Split text into words

  # Calculate word frequencies
  word_freq = {}
  for word in words:
      word = word.lower()
      if word.isalpha():  # Filter out non-alphabetic words
          if word in word_freq:
              word_freq[word] += 1
          else:
              word_freq[word] = 1

  # Calculate sentence scores based on word frequency and length
  sentence_scores = {}
  for sentence in sentences:
      if sentence.strip():  # Check if the sentence is not empty or just whitespace
          for word in word_freq:
              if word in sentence.lower():
                  if sentence in sentence_scores:
                        sentence_scores[sentence] += word_freq[word]
                  else:
                      sentence_scores[sentence] = word_freq[word]
          # Bonus points for longer sentences
          sentence_scores[sentence] += len(sentence.split())

  # Get the top N sentences with the highest scores
  num_sentences = 2  # Adjust the number of sentences you want in the summary
  summary_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]

  # Generate the final summary
  summary = '. '.join(summary_sentences)
  return summary


# Example usage:

# text = """
# Avocado Bistro offers a delightful dining experience. The restaurant's cozy ambiance sets the stage for a culinary adventure. The menu boasts a diverse selection of dishes, with a clear focus on fresh, locally sourced ingredients. The avocado-centric options are a must-try, from the creamy guacamole to the mouthwatering avocado toast. Service is impeccable, attentive without being intrusive. The wine list complements the menu nicely. Avocado Bistro is a gem for food enthusiasts seeking a farm-to-table experience with a twist. Prices are reasonable, making it an excellent choice for a memorable meal.
# """

# summary = summarize_text(text)

# print("summary is :- "+summary)

pip install translate

from translate import Translator

@anvil.server.callable


def translate_to_hindi(text):
    try:
        translator = Translator(to_lang="hi")
        hindi_translation = translator.translate(text)
        return hindi_translation
    except Exception as e:
        return str(e)

# Example usage:
english_text = "sunidhi is a beautiful girl and smart"
hindi_text = translate_to_hindi(english_text)
print(f"English: {english_text}")
print(f"Hindi: {hindi_text}")

"""import joblib
import numpy as np
import re
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer

# Define your custom tokenizer
class LemmaTokenizer(object):
    def __init__(self):
        self.wordnetlemma = WordNetLemmatizer()
    def __call__(self, reviews):
        return [self.wordnetlemma.lemmatize(word) for word in word_tokenize(reviews)]

# Define functions for data preprocessing
def remove_special_character(content):
    return re.sub('\W+', ' ', content)

def remove_url(content):
    return re.sub(r'http\S+', '', content)

def remove_stopwords(content):
    clean_data = []
    for i in content.split():
        i_stripped = i.strip()
        if i_stripped.lower() not in stop_words and i_stripped.isalpha():
            clean_data.append(i_stripped.lower())
    return " ".join(clean_data)

def contraction_expansion(content):
    content = re.sub(r"won\'t", "would not", content)
    content = re.sub(r"can\'t", "can not", content)
    # Add more contractions as needed
    return content

def preprocess_text(text_list):
    processed_texts = []
    for text in text_list:
        text = contraction_expansion(text)
        text = remove_special_character(text)
        text = remove_url(text)
        text = remove_stopwords(text)
        processed_texts.append(text)
    tfidf_vectorizer = TfidfVectorizer(
        analyzer="word",
        tokenizer=LemmaTokenizer(),
        ngram_range=(1, 3),
        min_df=1,
        max_features=10  # Adjust the number of features as needed
    )
    tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)
    return tfidf_matrix

# Load the pre-trained model
model_path = r'/content/senti.pkl'  # Replace with the actual path to your model
model = joblib.load(model_path)

# Define a function to predict sentiment
def predict_sentiment(input_text):
    preprocessed_text = preprocess_text([input_text])  # Pass input as a list
    prediction = model.predict(preprocessed_text)
    return int(prediction[0])  # Convert the prediction to an integer (0 or 1)

# Example usage:
input_text = "This is a great product!"  # Replace with your input text
sentiment = predict_sentiment(input_text)
print("Sentiment:", sentiment)

"""